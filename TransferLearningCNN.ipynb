{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "3288a36f4f016b57517aa6e0f71afa5d0639434f5b3fb8e1f938372155c796fd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Preprocessing\n",
    "- ### split the provided training set in 85% for actual training set and 15% to be used as validation set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "SEED = 1849\n",
    "image_size = (256, 256)\n",
    "class_names=['Bedroom', 'Coast', 'Forest', 'Highway', 'Industrial', 'InsideCity', 'Kitchen', 'LivingRoom', 'Mountain', 'Office', 'OpenCountry', 'Store', 'Street', 'Suburb', 'TallBuilding']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"dataset/train\",\n",
    "    color_mode=\"rgb\",\n",
    "    class_names=class_names,\n",
    "    validation_split=0.15,\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    image_size=image_size,\n",
    ")\n",
    "\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"dataset/train\",\n",
    "    color_mode=\"rgb\",\n",
    "    class_names=class_names,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    image_size=image_size,\n",
    ")\n",
    "\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"dataset/test\",\n",
    "    color_mode=\"rgb\",\n",
    "    class_names=class_names,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    image_size=image_size,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1500 files belonging to 15 classes.\n",
      "Using 1275 files for training.\n",
      "Found 1500 files belonging to 15 classes.\n",
      "Using 225 files for validation.\n",
      "Found 2985 files belonging to 15 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation of the training set\n",
    "- ### left-to-right reflection\n",
    "- ### random crop (cropping a patch of 240 x 240)\n",
    "- ### random rotation\n",
    "- ### resizing of the image (224 x 224)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "IMG_SIZE = 224\n",
    "CROP_SIZE = 240\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\", seed=SEED),\n",
    "        layers.experimental.preprocessing.RandomCrop(height=CROP_SIZE, width=CROP_SIZE, seed=SEED),\n",
    "        layers.experimental.preprocessing.RandomRotation(factor=0.1, seed=SEED),\n",
    "        layers.experimental.preprocessing.Resizing(height=IMG_SIZE, width=IMG_SIZE)\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_resizing = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Resizing(height=IMG_SIZE, width=IMG_SIZE)\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#just a preprocessing needed for the VGG19 model\n",
    "training_dataset_VGG19 = train_ds.map(lambda x, y: (tf.keras.applications.vgg19.preprocess_input(x), y))\n",
    "validation_dataset_VGG19 = val_ds.map(lambda x, y: (tf.keras.applications.vgg19.preprocess_input(x), y))\n",
    "test_dataset_VGG19 = test_ds.map(lambda x, y: (tf.keras.applications.vgg19.preprocess_input(x), y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "augmented_training_dataset = training_dataset_VGG19.map(lambda x, y: (data_augmentation(x), y))\n",
    "resized_training_dataset = training_dataset_VGG19.map(lambda x, y: (data_resizing(x), y))\n",
    "\n",
    "validation_dataset = validation_dataset_VGG19.map(lambda x, y: (data_resizing(x), y))\n",
    "test_dataset = test_dataset_VGG19.map(lambda x, y: (data_resizing(x), y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "training_dataset = augmented_training_dataset.concatenate(resized_training_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## VGG19 loading..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "VGG19_model = VGG19(weights='imagenet', input_shape=(224,224,3), include_top=True)\n",
    "VGG19_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's remove the last layer and add the new final dense layer manually"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "bias_init = initializers.Zeros()\n",
    "weight_init = initializers.RandomNormal(mean=0, stddev=0.01)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "for layer in VGG19_model.layers[:-1]:\n",
    "\tmodel.add(layer)\n",
    "\n",
    "model.add(layers.Dense(units=num_classes, bias_initializer=bias_init, kernel_initializer=weight_init, activation=\"softmax\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now freeze all the layers except the last"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 15)                61455     \n",
      "=================================================================\n",
      "Total params: 139,631,695\n",
      "Trainable params: 61,455\n",
      "Non-trainable params: 139,570,240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Starting the fine-tuning.."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "opt = optimizers.Adam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3,\n",
    "restore_best_weights=True)\n",
    "\n",
    "minibatches = 32\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(training_dataset, validation_data=validation_dataset, batch_size=minibatches, epochs=epochs,\n",
    "callbacks=[early_stopping], shuffle=True, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 359s 4s/step - loss: 1.1675 - accuracy: 0.6002 - val_loss: 0.4818 - val_accuracy: 0.8267\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 367s 5s/step - loss: 0.3236 - accuracy: 0.8862 - val_loss: 0.4197 - val_accuracy: 0.8267\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 369s 5s/step - loss: 0.2503 - accuracy: 0.9128 - val_loss: 0.4155 - val_accuracy: 0.8533\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 366s 5s/step - loss: 0.2159 - accuracy: 0.9213 - val_loss: 0.3907 - val_accuracy: 0.8756\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 367s 5s/step - loss: 0.1823 - accuracy: 0.9399 - val_loss: 0.4495 - val_accuracy: 0.8578\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "test_eval = model.evaluate(test_dataset, verbose=0)\n",
    "print('Overall Test accuracy: {number:.{digits}f}'.format(number=test_eval[1], digits=2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overall Test accuracy: 0.88\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's employ the VGG19 as a feature extractor for the SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "feature_extractor_model = VGG19(weights='imagenet', input_shape=(224,224,3), include_top=False)\n",
    "feature_extractor_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "test_list = list(test_dataset) #casting necessary due to the randomized iteration over the datasets\n",
    "test_labels = np.concatenate([y for x, y in test_list], axis=0)\n",
    "test_images = np.concatenate([x for x, y in test_list], axis=0)\n",
    "\n",
    "training_list = list(training_dataset)\n",
    "training_labels = np.concatenate([y for x, y in training_list], axis=0)\n",
    "training_images = np.concatenate([x for x, y in training_list], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "features = feature_extractor_model.predict(training_images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Just flattening the feature dimensions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "nsamples, x, y, z = features.shape\n",
    "features_reshaped = features.reshape(nsamples, x*y*z)\n",
    "features_reshaped.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2550, 25088)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the linear SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn import svm\n",
    "\n",
    "linear_clf = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(features_reshaped, training_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the non-linear SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "clf = svm.SVC(gamma='auto', C=1, decision_function_shape='ovo').fit(features_reshaped, training_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract features from the test dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "test_features = feature_extractor_model.predict(test_images)\n",
    "nsamples, x, y, z = test_features.shape\n",
    "test_features_reshaped = test_features.reshape(nsamples, x*y*z)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the linear SVM on the test dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "y_pred = linear_clf.predict(features_reshaped)\n",
    "print(\"Training Accuracy:\",metrics.accuracy_score(training_labels, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy: 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "y_pred = linear_clf.predict(test_features_reshaped)\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(test_labels, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 0.8954773869346734\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the non-linear SVM on the test dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "y_pred = clf.predict(features_reshaped)\n",
    "print(\"Training Accuracy:\",metrics.accuracy_score(training_labels, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy: 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "y_pred = clf.predict(test_features_reshaped)\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(test_labels, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 0.06834170854271357\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discussion on SVM\n",
    "\n",
    "As we can see, the 2 SVMs overfit (a lot), but the linear one have a good test accuracy!\n",
    "\n",
    "The non linear SVM instead is worse then a random classifier! \n",
    "\n",
    "(random classifier -> 7% accuracy)"
   ],
   "metadata": {}
  }
 ]
}